"""
MAIFA v3 Service Mesh + Horizontal Scaling
Distributed service mesh with auto-scaling, load balancing, and failover
"""

import asyncio
import json
import time
import logging
import hashlib
from typing import Dict, List, Any, Optional, Set, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from enum import Enum
import aiohttp
import consul
from consul import ConsulException

from core.distributed_state import distributed_state_manager
from utils.logger import get_logger
from utils.helpers import TimeHelper, HashHelper

logger = get_logger("service_mesh")

class ServiceStatus(Enum):
    HEALTHY = "healthy"
    UNHEALTHY = "unhealthy"
    DEGRADED = "degraded"
    MAINTENANCE = "maintenance"

class Priority(Enum):
    CRITICAL = 1    # High-priority agents (risk analysis, trading signals)
    HIGH = 2        # Important agents (sentiment, classification)
    NORMAL = 3      # Regular agents (filtering, preprocessing)
    LOW = 4         # Background agents (monitoring, cleanup)

@dataclass
class ServiceInstance:
    """Individual service instance information"""
    instance_id: str
    service_name: str
    host: str
    port: int
    status: ServiceStatus
    priority: Priority
    metadata: Dict[str, Any]
    last_heartbeat: float
    health_check_url: str
    load_factor: float = 0.0
    active_requests: int = 0
    max_requests: int = 100

@dataclass
class ServiceConfig:
    """Service mesh configuration"""
    consul_host: str = "localhost"
    consul_port: int = 8500
    health_check_interval: int = 10
    health_check_timeout: int = 5
    deregister_critical_after: int = 30
    auto_scaling_enabled: bool = True
    min_instances: int = 2
    max_instances: int = 10
    scale_up_threshold: float = 0.8  # 80% load
    scale_down_threshold: float = 0.2  # 20% load
    scale_up_cooldown: int = 60  # seconds
    scale_down_cooldown: int = 120  # seconds

class ServiceMesh:
    """
    High-performance service mesh with horizontal scaling
    
    Features:
    - Service discovery with Consul
    - Automatic load balancing
    - Dynamic auto-scaling
    - Health monitoring and failover
    - Priority-based request routing
    - Circuit breaker integration
    """
    
    def __init__(self, config: ServiceConfig):
        self.config = config
        self.logger = get_logger("ServiceMesh")
        self.consul_client = None
        self.service_registry: Dict[str, List[ServiceInstance]] = {}
        self.load_balancers: Dict[str, "LoadBalancer"] = {}
        self.health_checkers: Dict[str, asyncio.Task] = {}
        self.auto_scalers: Dict[str, asyncio.Task] = {}
        self.is_running = False
        
        # Performance metrics
        self.metrics = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "avg_response_time": 0.0,
            "active_instances": 0,
            "scaling_events": 0,
            "failover_events": 0
        }
        
        # Scaling cooldowns
        self.last_scale_up: Dict[str, float] = {}
        self.last_scale_down: Dict[str, float] = {}
    
    async def initialize(self) -> bool:
        """Initialize service mesh with Consul"""
        try:
            self.logger.info("ðŸ”§ Initializing Service Mesh...")
            
            # Initialize Consul client
            self.consul_client = consul.Consul(
                host=self.config.consul_host,
                port=self.config.consul_port
            )
            
            # Test Consul connection
            await self._test_consul_connection()
            
            # Start background tasks
            self.is_running = True
            asyncio.create_task(self._service_discovery_loop())
            asyncio.create_task(self._metrics_collection_loop())
            
            self.logger.info("âœ… Service Mesh initialized successfully")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Service Mesh initialization failed: {e}")
            return False
    
    async def _test_consul_connection(self):
        """Test Consul connection"""
        try:
            # Test basic Consul operations
            await asyncio.get_event_loop().run_in_executor(
                None, self.consul_client.agent.self
            )
            
            self.logger.info("âœ… Consul connection test passed")
            
        except Exception as e:
            self.logger.error(f"âŒ Consul connection test failed: {e}")
            raise
    
    async def register_service(self, 
                             service_name: str,
                             instance_id: str,
                             host: str,
                             port: int,
                             health_check_url: str,
                             priority: Priority = Priority.NORMAL,
                             metadata: Dict[str, Any] = None) -> bool:
        """
        Register service instance with Consul
        
        Args:
            service_name: Name of the service
            instance_id: Unique instance identifier
            host: Service host address
            port: Service port
            health_check_url: Health check endpoint
            priority: Service priority for load balancing
            metadata: Additional service metadata
        """
        try:
            # Create service instance
            instance = ServiceInstance(
                instance_id=instance_id,
                service_name=service_name,
                host=host,
                port=port,
                status=ServiceStatus.HEALTHY,
                priority=priority,
                metadata=metadata or {},
                last_heartbeat=time.time(),
                health_check_url=health_check_url,
                max_requests=metadata.get("max_requests", 100) if metadata else 100
            )
            
            # Register with Consul
            consul_service_id = f"{service_name}-{instance_id}"
            
            def register_with_consul():
                return self.consul_client.agent.service.register(
                    name=service_name,
                    service_id=consul_service_id,
                    address=host,
                    port=port,
                    check=consul.Check.http(
                        url=f"http://{host}:{port}{health_check_url}",
                        interval=f"{self.config.health_check_interval}s",
                        timeout=f"{self.config.health_check_timeout}s",
                        deregister_critical_service_after=f"{self.config.deregister_critical_after}s"
                    ),
                    meta=metadata or {}
                )
            
            await asyncio.get_event_loop().run_in_executor(
                None, register_with_consul
            )
            
            # Add to local registry
            if service_name not in self.service_registry:
                self.service_registry[service_name] = []
                self.load_balancers[service_name] = LoadBalancer(service_name)
                self.health_checkers[service_name] = asyncio.create_task(
                    self._health_check_loop(service_name)
                )
                self.auto_scalers[service_name] = asyncio.create_task(
                    self._auto_scaling_loop(service_name)
                )
            
            self.service_registry[service_name].append(instance)
            
            # Store in distributed state
            await distributed_state_manager.set_state(
                f"service:{service_name}:{instance_id}",
                asdict(instance),
                ttl=self.config.deregister_critical_after * 2
            )
            
            self.logger.info(f"ðŸ“ Service registered: {service_name}/{instance_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to register service {service_name}/{instance_id}: {e}")
            return False
    
    async def deregister_service(self, service_name: str, instance_id: str) -> bool:
        """Deregister service instance"""
        try:
            # Deregister from Consul
            consul_service_id = f"{service_name}-{instance_id}"
            
            def deregister_from_consul():
                return self.consul_client.agent.service.deregister(consul_service_id)
            
            await asyncio.get_event_loop().run_in_executor(
                None, deregister_from_consul
            )
            
            # Remove from local registry
            if service_name in self.service_registry:
                self.service_registry[service_name] = [
                    inst for inst in self.service_registry[service_name]
                    if inst.instance_id != instance_id
                ]
            
            # Remove from distributed state
            await distributed_state_manager.delete_state(
                f"service:{service_name}:{instance_id}"
            )
            
            self.logger.info(f"ðŸ—‘ï¸ Service deregistered: {service_name}/{instance_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to deregister service {service_name}/{instance_id}: {e}")
            return False
    
    async def call_service(self, 
                          service_name: str,
                          request_data: Dict[str, Any],
                          timeout: float = 5.0,
                          priority: Optional[Priority] = None) -> Optional[Dict[str, Any]]:
        """
        Call service with intelligent load balancing and failover
        
        Args:
            service_name: Target service name
            request_data: Request payload
            timeout: Request timeout
            priority: Request priority (overrides service priority)
        """
        start_time = time.time()
        
        try:
            # Get healthy instances
            healthy_instances = await self._get_healthy_instances(service_name)
            
            if not healthy_instances:
                self.logger.warning(f"âš ï¸ No healthy instances for service: {service_name}")
                self.metrics["failed_requests"] += 1
                return None
            
            # Select instance using load balancer
            selected_instance = self.load_balancers[service_name].select_instance(
                healthy_instances, priority
            )
            
            if not selected_instance:
                self.logger.warning(f"âš ï¸ Load balancer failed to select instance for: {service_name}")
                self.metrics["failed_requests"] += 1
                return None
            
            # Make request with circuit breaker
            result = await self._make_request_with_circuit_breaker(
                selected_instance, request_data, timeout
            )
            
            # Update metrics
            execution_time = time.time() - start_time
            self._update_metrics(execution_time, result is not None)
            
            # Update instance metrics
            selected_instance.active_requests = max(0, selected_instance.active_requests - 1)
            selected_instance.load_factor = selected_instance.active_requests / selected_instance.max_requests
            
            return result
            
        except Exception as e:
            execution_time = time.time() - start_time
            self._update_metrics(execution_time, False)
            self.logger.error(f"âŒ Service call failed for {service_name}: {e}")
            return None
    
    async def _get_healthy_instances(self, service_name: str) -> List[ServiceInstance]:
        """Get healthy instances for a service"""
        if service_name not in self.service_registry:
            # Try to load from distributed state
            await self._load_service_from_state(service_name)
        
        if service_name not in self.service_registry:
            return []
        
        # Filter healthy instances
        healthy_instances = [
            inst for inst in self.service_registry[service_name]
            if inst.status == ServiceStatus.HEALTHY
            and inst.active_requests < inst.max_requests
        ]
        
        return healthy_instances
    
    async def _load_service_from_state(self, service_name: str):
        """Load service instances from distributed state"""
        try:
            # Get all service instances from state
            pattern = f"service:{service_name}:*"
            # Note: This would need Redis pattern matching implementation
            # For now, we'll use Consul discovery
            
            # Discover from Consul
            def discover_from_consul():
                return self.consul_client.health.service(service_name, passing=True)
            
            services, _ = await asyncio.get_event_loop().run_in_executor(
                None, discover_from_consul
            )
            
            instances = []
            for service in services:
                service_info = service['Service']
                instance = ServiceInstance(
                    instance_id=service_info['ID'].replace(f"{service_name}-", ""),
                    service_name=service_name,
                    host=service_info['Address'],
                    port=service_info['Port'],
                    status=ServiceStatus.HEALTHY,
                    priority=Priority.NORMAL,
                    metadata=service_info.get('Meta', {}),
                    last_heartbeat=time.time(),
                    health_check_url="/health",
                    max_requests=100
                )
                instances.append(instance)
            
            self.service_registry[service_name] = instances
            self.load_balancers[service_name] = LoadBalancer(service_name)
            
            self.logger.info(f"ðŸ“¥ Loaded {len(instances)} instances for service: {service_name}")
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to load service {service_name} from state: {e}")
    
    async def _make_request_with_circuit_breaker(self,
                                                instance: ServiceInstance,
                                                request_data: Dict[str, Any],
                                                timeout: float) -> Optional[Dict[str, Any]]:
        """Make HTTP request with circuit breaker protection"""
        try:
            # Increment active requests
            instance.active_requests += 1
            
            # Make request
            url = f"http://{instance.host}:{instance.port}/process"
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    url,
                    json=request_data,
                    timeout=aiohttp.ClientTimeout(total=timeout)
                ) as response:
                    if response.status == 200:
                        return await response.json()
                    else:
                        self.logger.warning(f"âš ï¸ Service {instance.instance_id} returned status {response.status}")
                        return None
                        
        except asyncio.TimeoutError:
            self.logger.warning(f"âš ï¸ Service {instance.instance_id} timeout")
            return None
        except Exception as e:
            self.logger.error(f"âŒ Service {instance.instance_id} request failed: {e}")
            return None
    
    async def _service_discovery_loop(self):
        """Background service discovery and synchronization"""
        while self.is_running:
            try:
                await asyncio.sleep(30)  # Sync every 30 seconds
                
                # Sync with Consul
                await self._sync_with_consul()
                
                # Update metrics
                total_instances = sum(len(instances) for instances in self.service_registry.values())
                self.metrics["active_instances"] = total_instances
                
            except Exception as e:
                self.logger.error(f"âŒ Service discovery error: {e}")
    
    async def _sync_with_consul(self):
        """Synchronize local registry with Consul"""
        try:
            # Get all services from Consul
            def get_all_services():
                return self.consul_client.agent.services()
            
            consul_services = await asyncio.get_event_loop().run_in_executor(
                None, get_all_services
            )
            
            # Update local registry
            for service_id, service_info in consul_services.items():
                service_name = service_info['Service']
                
                if service_name not in self.service_registry:
                    self.service_registry[service_name] = []
                    self.load_balancers[service_name] = LoadBalancer(service_name)
                
                # Check if instance exists locally
                instance_id = service_id.replace(f"{service_name}-", "")
                exists = any(
                    inst.instance_id == instance_id 
                    for inst in self.service_registry[service_name]
                )
                
                if not exists:
                    # Add new instance
                    instance = ServiceInstance(
                        instance_id=instance_id,
                        service_name=service_name,
                        host=service_info['Address'],
                        port=service_info['Port'],
                        status=ServiceStatus.HEALTHY,
                        priority=Priority.NORMAL,
                        metadata=service_info.get('Meta', {}),
                        last_heartbeat=time.time(),
                        health_check_url="/health",
                        max_requests=100
                    )
                    self.service_registry[service_name].append(instance)
                    
        except Exception as e:
            self.logger.error(f"âŒ Consul sync failed: {e}")
    
    async def _health_check_loop(self, service_name: str):
        """Health monitoring for service instances"""
        while self.is_running:
            try:
                await asyncio.sleep(self.config.health_check_interval)
                
                if service_name not in self.service_registry:
                    continue
                
                for instance in self.service_registry[service_name]:
                    await self._check_instance_health(instance)
                    
            except Exception as e:
                self.logger.error(f"âŒ Health check error for {service_name}: {e}")
    
    async def _check_instance_health(self, instance: ServiceInstance):
        """Check individual instance health"""
        try:
            # Make health check request
            url = f"http://{instance.host}:{instance.port}{instance.health_check_url}"
            
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    url,
                    timeout=aiohttp.ClientTimeout(total=self.config.health_check_timeout)
                ) as response:
                    if response.status == 200:
                        instance.status = ServiceStatus.HEALTHY
                        instance.last_heartbeat = time.time()
                    else:
                        instance.status = ServiceStatus.UNHEALTHY
                        
        except Exception as e:
            instance.status = ServiceStatus.UNHEALTHY
            self.logger.debug(f"Health check failed for {instance.instance_id}: {e}")
    
    async def _auto_scaling_loop(self, service_name: str):
        """Auto-scaling based on load metrics"""
        while self.is_running and self.config.auto_scaling_enabled:
            try:
                await asyncio.sleep(30)  # Check every 30 seconds
                
                if service_name not in self.service_registry:
                    continue
                
                instances = self.service_registry[service_name]
                
                # Calculate average load
                if not instances:
                    continue
                
                avg_load = sum(inst.load_factor for inst in instances) / len(instances)
                
                # Check scale up conditions
                current_time = time.time()
                
                if (avg_load > self.config.scale_up_threshold and 
                    len(instances) < self.config.max_instances and
                    current_time - self.last_scale_up.get(service_name, 0) > self.config.scale_up_cooldown):
                    
                    await self._scale_up(service_name)
                    self.last_scale_up[service_name] = current_time
                    self.metrics["scaling_events"] += 1
                
                # Check scale down conditions
                elif (avg_load < self.config.scale_down_threshold and 
                      len(instances) > self.config.min_instances and
                      current_time - self.last_scale_down.get(service_name, 0) > self.config.scale_down_cooldown):
                    
                    await self._scale_down(service_name)
                    self.last_scale_down[service_name] = current_time
                    self.metrics["scaling_events"] += 1
                    
            except Exception as e:
                self.logger.error(f"âŒ Auto-scaling error for {service_name}: {e}")
    
    async def _scale_up(self, service_name: str):
        """Scale up service by adding new instance"""
        try:
            self.logger.info(f"ðŸ“ˆ Scaling up service: {service_name}")
            
            # This would integrate with container orchestration (Kubernetes, Docker Swarm)
            # For now, we'll just log the scaling event
            
            # In production, this would:
            # 1. Call Kubernetes API to create new pod
            # 2. Wait for pod to be ready
            # 3. Register new instance with service mesh
            
            self.logger.info(f"âœ… Scale up initiated for {service_name}")
            
        except Exception as e:
            self.logger.error(f"âŒ Scale up failed for {service_name}: {e}")
    
    async def _scale_down(self, service_name: str):
        """Scale down service by removing instance"""
        try:
            self.logger.info(f"ðŸ“‰ Scaling down service: {service_name}")
            
            if service_name not in self.service_registry:
                return
            
            instances = self.service_registry[service_name]
            
            # Find instance with lowest load
            lowest_load_instance = min(instances, key=lambda inst: inst.load_factor)
            
            # Deregister instance
            await self.deregister_service(service_name, lowest_load_instance.instance_id)
            
            self.logger.info(f"âœ… Scale down completed for {service_name}")
            
        except Exception as e:
            self.logger.error(f"âŒ Scale down failed for {service_name}: {e}")
    
    async def _metrics_collection_loop(self):
        """Background metrics collection"""
        while self.is_running:
            try:
                await asyncio.sleep(300)  # Collect every 5 minutes
                
                # Log metrics
                self.logger.info(f"ðŸ“Š Service Mesh Metrics: {self.metrics}")
                
                # Store metrics in distributed state
                await distributed_state_manager.set_state(
                    "service_mesh:metrics",
                    self.metrics,
                    ttl=3600
                )
                
            except Exception as e:
                self.logger.error(f"âŒ Metrics collection error: {e}")
    
    def _update_metrics(self, response_time: float, success: bool):
        """Update performance metrics"""
        self.metrics["total_requests"] += 1
        
        if success:
            self.metrics["successful_requests"] += 1
        else:
            self.metrics["failed_requests"] += 1
        
        # Update average response time
        total = self.metrics["total_requests"]
        current_avg = self.metrics["avg_response_time"]
        self.metrics["avg_response_time"] = (current_avg * (total - 1) + response_time) / total
    
    async def get_service_status(self, service_name: str) -> Dict[str, Any]:
        """Get comprehensive service status"""
        try:
            if service_name not in self.service_registry:
                return {"error": f"Service {service_name} not found"}
            
            instances = self.service_registry[service_name]
            
            status = {
                "service_name": service_name,
                "total_instances": len(instances),
                "healthy_instances": len([inst for inst in instances if inst.status == ServiceStatus.HEALTHY]),
                "unhealthy_instances": len([inst for inst in instances if inst.status == ServiceStatus.UNHEALTHY]),
                "avg_load_factor": sum(inst.load_factor for inst in instances) / len(instances) if instances else 0,
                "active_requests": sum(inst.active_requests for inst in instances),
                "instances": [asdict(inst) for inst in instances],
                "load_balancer": self.load_balancers[service_name].get_status() if service_name in self.load_balancers else None,
                "timestamp": datetime.now().isoformat()
            }
            
            return status
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to get service status {service_name}: {e}")
            return {"error": str(e)}
    
    async def get_mesh_status(self) -> Dict[str, Any]:
        """Get overall service mesh status"""
        try:
            return {
                "is_running": self.is_running,
                "total_services": len(self.service_registry),
                "total_instances": sum(len(instances) for instances in self.service_registry.values()),
                "metrics": self.metrics,
                "config": asdict(self.config),
                "services": {
                    name: await self.get_service_status(name)
                    for name in self.service_registry.keys()
                },
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to get mesh status: {e}")
            return {"error": str(e)}
    
    async def shutdown(self):
        """Graceful shutdown"""
        try:
            self.logger.info("ðŸ›‘ Shutting down Service Mesh...")
            
            self.is_running = False
            
            # Cancel background tasks
            for task in self.health_checkers.values():
                task.cancel()
            
            for task in self.auto_scalers.values():
                task.cancel()
            
            # Deregister all services
            for service_name, instances in self.service_registry.items():
                for instance in instances:
                    await self.deregister_service(service_name, instance.instance_id)
            
            self.logger.info("âœ… Service Mesh shutdown complete")
            
        except Exception as e:
            self.logger.error(f"âŒ Shutdown error: {e}")


class LoadBalancer:
    """Intelligent load balancer with priority routing"""
    
    def __init__(self, service_name: str):
        self.service_name = service_name
        self.logger = get_logger(f"LoadBalancer.{service_name}")
        self.algorithm = "weighted_round_robin"
        self.current_index = 0
        self.metrics = {
            "total_selections": 0,
            "priority_distributions": {p.value: 0 for p in Priority}
        }
    
    def select_instance(self, 
                       instances: List[ServiceInstance], 
                       request_priority: Optional[Priority] = None) -> Optional[ServiceInstance]:
        """Select best instance based on load and priority"""
        if not instances:
            return None
        
        try:
            # Filter by priority if specified
            if request_priority:
                priority_instances = [
                    inst for inst in instances 
                    if inst.priority == request_priority
                ]
                if priority_instances:
                    instances = priority_instances
            
            # Sort by load factor (lowest first)
            instances.sort(key=lambda inst: inst.load_factor)
            
            # Select instance with lowest load
            selected = instances[0]
            
            # Update metrics
            self.metrics["total_selections"] += 1
            self.metrics["priority_distributions"][selected.priority.value] += 1
            
            self.logger.debug(f"ðŸŽ¯ Selected instance {selected.instance_id} (load: {selected.load_factor:.2f})")
            
            return selected
            
        except Exception as e:
            self.logger.error(f"âŒ Instance selection failed: {e}")
            return None
    
    def get_status(self) -> Dict[str, Any]:
        """Get load balancer status"""
        return {
            "service_name": self.service_name,
            "algorithm": self.algorithm,
            "metrics": self.metrics,
            "timestamp": datetime.now().isoformat()
        }


# Global service mesh instance
service_mesh_config = ServiceConfig(
    consul_host="localhost",
    consul_port=8500,
    auto_scaling_enabled=True,
    min_instances=2,
    max_instances=10
)

service_mesh = ServiceMesh(service_mesh_config)
