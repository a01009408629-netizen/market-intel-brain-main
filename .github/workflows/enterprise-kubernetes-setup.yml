name: ðŸš€ Enterprise Kubernetes Setup

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        default: 'production'
        type: choice
        options:
          - production
          - staging
          - development
      setup_type:
        description: 'Setup type'
        required: true
        default: 'full'
        type: choice
        options:
          - full
          - k3s-only
          - databases-only
          - monitoring-only

jobs:
  # ===== K3S ORCHESTRATOR SETUP =====
  setup-k3s-orchestrator:
    name: ðŸŽ¯ Setup K3s Orchestrator
    runs-on: ubuntu-latest
    if: github.event.inputs.setup_type == 'full' || github.event.inputs.setup_type == 'k3s-only'
    
    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸŽ¯ Create K3s Setup Scripts
        run: |
          mkdir -p k3s-setup/{scripts,configs,manifests}

      - name: ðŸŽ¯ K3s Installation Script
        run: |
          cat > k3s-setup/scripts/install-k3s.sh << 'EOF'
          #!/bin/bash
          set -e

          echo "ðŸŽ¯ Installing K3s Kubernetes..."

          # System update
          sudo apt update && sudo apt upgrade -y

          # Install required packages
          sudo apt install -y curl wget gnupg2 software-properties-common apt-transport-https ca-certificates

          # Disable swap
          sudo swapoff -a
          sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab

          # Configure kernel modules
          cat <<EOF | sudo tee /etc/modules-load.d/k3s.conf
          br_netfilter
          overlay
          EOF

          sudo modprobe br_netfilter
          sudo modprobe overlay

          # Configure sysctl
          cat <<EOF | sudo tee /etc/sysctl.d/k3s.conf
          net.bridge.bridge-nf-call-iptables  = 1
          net.bridge.bridge-nf-call-ip6tables = 1
          net.ipv4.ip_forward                 = 1
          EOF

          sudo sysctl --system

          # Install K3s
          curl -sfL https://get.k3s.io | sh -s - --write-kubeconfig-mode 644

          # Start K3s
          sudo systemctl enable --now k3s

          # Setup kubectl
          mkdir -p ~/.kube
          sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config
          sudo chown $USER:$USER ~/.kube/config
          chmod 600 ~/.kube/config

          # Install Helm
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

          # Verify installation
          kubectl version --client
          helm version

          echo "âœ… K3s and Helm installed successfully!"
          EOF

          chmod +x k3s-setup/scripts/install-k3s.sh

      - name: ðŸ“¦ Helm Charts Setup
        run: |
          cat > k3s-setup/scripts/setup-helm.sh << 'EOF'
          #!/bin/bash
          set -e

          echo "ðŸ“¦ Setting up Helm repositories..."

          # Add essential Helm repositories
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo add grafana https://grafana.github.io/helm-charts
          helm repo add redpanda https://vectorized.io/redpanda-charts
          helm repo add timescale https://charts.timescale.com/
          helm repo add bitnami https://charts.bitnami.com/bitnami
          helm repo update

          echo "âœ… Helm repositories configured!"
          EOF

          chmod +x k3s-setup/scripts/setup-helm.sh

      - name: ðŸ—„ï¸ Storage Configuration
        run: |
          cat > k3s-setup/manifests/storage.yaml << 'EOF'
          apiVersion: v1
          kind: PersistentVolume
          metadata:
            name: ssd-storage-pv
            namespace: market-intel
          spec:
            capacity:
              storage: 100Gi
            accessModes:
              - ReadWriteOnce
            persistentVolumeReclaimPolicy: Retain
            storageClassName: local-path
            hostPath:
              path: /mnt/data/ssd-storage
          ---
          apiVersion: v1
          kind: PersistentVolumeClaim
          metadata:
            name: ssd-storage-pvc
            namespace: market-intel
          spec:
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 50Gi
            storageClassName: local-path
          EOF

      - name: ðŸ“¤ Upload K3s Setup
        uses: actions/upload-artifact@v4
        with:
          name: k3s-orchestrator
          path: k3s-setup/
          retention-days: 30

  # ===== REDPANDA MESSAGE BROKER =====
  setup-redpanda-broker:
    name: ðŸš€ Setup Redpanda Message Broker
    runs-on: ubuntu-latest
    if: github.event.inputs.setup_type == 'full'
    needs: setup-k3s-orchestrator
    
    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸš€ Create Redpanda Configuration
        run: |
          mkdir -p redpanda-setup/{charts,configs}

      - name: ðŸ“¨ Redpanda Helm Chart
        run: |
          cat > redpanda-setup/charts/redpanda-values.yaml << 'EOF'
          global:
            storageClass: local-path

          redpanda:
            nodeCount: 3
            resources:
              cpu:
                requests: 2
                limits: 4
              memory:
                requests: 4Gi
                limits: 8Gi
              volume:
                size: 50Gi
                storageClass: local-path

            configuration:
              admin_api:
                - name: admin_api
                  address: 0.0.0.0
                  port: 9644
              kafka_api:
                - name: kafka_api
                  address: 0.0.0.0
                  port: 9092
              pandaproxy:
                - name: pandaproxy
                  address: 0.0.0.0
                  port: 8082
                  admin:
                    port: 9644
              auto_create_topics: true
              default_topic_partitions: 3
              default_topic_replications: 3
              enable_transactions: true
              enable_idempotence: true
              transaction_timeout_ms: 30000

            external:
              enabled: true
              type: LoadBalancer

            tls:
              enabled: false

            monitoring:
              enabled: true
          EOF

      - name: ðŸ“¨ Redpanda Topics Setup
        run: |
          cat > redpanda-setup/configs/topics.yaml << 'EOF'
          apiVersion: kafka.strimzi.io/v1beta2
          kind: KafkaTopic
          metadata:
            name: market-data-stream
            namespace: market-intel
            labels:
              strimzi.io/cluster: redpanda
          spec:
            partitions: 6
            replicas: 3
            config:
              retention.ms: 86400000  # 24 hours
              segment.bytes: 1073741824  # 1GB
              cleanup.policy: delete
          ---
          apiVersion: kafka.strimzi.io/v1beta2
          kind: KafkaTopic
          metadata:
            name: sentiment-analysis-stream
            namespace: market-intel
            labels:
              strimzi.io/cluster: redpanda
          spec:
            partitions: 3
            replicas: 3
            config:
              retention.ms: 86400000
              segment.bytes: 536870912  # 512MB
              cleanup.policy: delete
          ---
          apiVersion: kafka.strimzi.io/v1beta2
          kind: KafkaTopic
          metadata:
            name: technical-indicators-stream
            namespace: market-intel
            labels:
              strimzi.io/cluster: redpanda
          spec:
            partitions: 3
            replicas: 3
            config:
              retention.ms: 86400000
              segment.bytes: 536870912
              cleanup.policy: delete
          EOF

      - name: ðŸš€ Redpanda Deployment Script
        run: |
          cat > redpanda-setup/scripts/deploy-redpanda.sh << 'EOF'
          #!/bin/bash
          set -e

          echo "ðŸš€ Deploying Redpanda message broker..."

          # Create namespace
          kubectl create namespace market-intel --dry-run=client -o yaml | kubectl apply -f -

          # Add Redpanda Helm repo
          helm repo add redpanda https://vectorized.io/redpanda-charts
          helm repo update

          # Install Redpanda
          helm install redpanda redpanda/redpanda \
            --namespace market-intel \
            --values redpanda-values.yaml \
            --wait

          # Create topics
          kubectl apply -f topics.yaml

          # Verify deployment
          kubectl get pods -n market-intel
          kubectl get services -n market-intel

          echo "âœ… Redpanda deployed successfully!"
          EOF

          chmod +x redpanda-setup/scripts/deploy-redpanda.sh

      - name: ðŸ“¤ Upload Redpanda Setup
        uses: actions/upload-artifact@v4
        with:
          name: redpanda-broker
          path: redpanda-setup/
          retention-days: 30

  # ===== DATABASES SETUP =====
  setup-databases:
    name: ðŸ—„ï¸ Setup Databases
    runs-on: ubuntu-latest
    if: github.event.inputs.setup_type == 'full' || github.event.inputs.setup_type == 'databases-only'
    
    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸ—„ï¸ Create Database Configurations
        run: |
          mkdir -p databases-setup/{charts,configs,manifests}

      - name: ðŸ˜ TimescaleDB Configuration
        run: |
          cat > databases-setup/charts/timescaledb-values.yaml << 'EOF'
          auth:
            postgresPassword: "marketintel123"
            replicationPassword: "repl123"
          primary:
            persistence:
              enabled: true
              size: 20Gi
              storageClass: local-path
            resources:
              requests:
                memory: 2Gi
                cpu: 1000m
              limits:
                memory: 4Gi
                cpu: 2000m
            extendedConfiguration: |
              shared_preload_libraries = 'timescaledb'
              max_connections = 200
              shared_buffers = 256MB
              effective_cache_size = 1GB
              work_mem = 4MB
              maintenance_work_mem = 64MB
              checkpoint_completion_target = 0.9
              wal_buffers = 16MB
              default_statistics_target = 100
          readReplicas:
            replicaCount: 1
            persistence:
              size: 10Gi
              storageClass: local-path
          EOF

      - name: ðŸ§  Qdrant Configuration
        run: |
          cat > databases-setup/charts/qdrant-values.yaml << 'EOF'
          replicaCount: 1
          image:
            tag: latest
          resources:
            requests:
              memory: 1Gi
              cpu: 500m
            limits:
              memory: 2Gi
              cpu: 1000m
          persistence:
            enabled: true
            size: 10Gi
            storageClass: local-path
          service:
            type: ClusterIP
            port: 6333
          config:
            log_level: INFO
            storage:
              performance:
                max_search_threads: 4
                max_vector_size_bytes: 1048576
            service:
              http_port: 6333
              grpc_port: 6334
          EOF

      - name: ðŸ”´ Redis Configuration
        run: |
          cat > databases-setup/charts/redis-values.yaml << 'EOF'
          auth:
            enabled: true
            password: "redis123"
          master:
            persistence:
              enabled: true
              size: 8Gi
              storageClass: local-path
            resources:
              requests:
                memory: 512Mi
                cpu: 250m
              limits:
                memory: 1Gi
                cpu: 500m
          replica:
            replicaCount: 1
            resources:
              requests:
                memory: 256Mi
                cpu: 100m
              limits:
                memory: 512Mi
                cpu: 250m
          metrics:
            enabled: true
          EOF

      - name: ðŸ—„ï¸ Database Deployment Script
        run: |
          cat > databases-setup/scripts/deploy-databases.sh << 'EOF'
          #!/bin/bash
          set -e

          echo "ðŸ—„ï¸ Deploying databases..."

          # Create namespace
          kubectl create namespace market-intel --dry-run=client -o yaml | kubectl apply -f -

          # Add repositories
          helm repo add timescale https://charts.timescale.com/
          helm repo add qdrant https://qdrant.github.io/qdrant-helm
          helm repo add bitnami https://charts.bitnami.com/bitnami
          helm repo update

          # Install TimescaleDB
          helm install timescaledb timescale/timescaledb-single \
            --namespace market-intel \
            --values timescaledb-values.yaml \
            --wait

          # Install Qdrant
          helm install qdrant qdrant/qdrant \
            --namespace market-intel \
            --values qdrant-values.yaml \
            --wait

          # Install Redis
          helm install redis bitnami/redis \
            --namespace market-intel \
            --values redis-values.yaml \
            --wait

          # Wait for databases to be ready
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=timescaledb -n market-intel --timeout=300s
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=qdrant -n market-intel --timeout=300s
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=redis -n market-intel --timeout=300s

          echo "âœ… Databases deployed successfully!"
          EOF

          chmod +x databases-setup/scripts/deploy-databases.sh

      - name: ðŸ“¤ Upload Database Setup
        uses: actions/upload-artifact@v4
        with:
          name: databases-setup
          path: databases-setup/
          retention-days: 30

  # ===== MONITORING SETUP =====
  setup-monitoring:
    name: ðŸ“Š Setup Monitoring Stack
    runs-on: ubuntu-latest
    if: github.event.inputs.setup_type == 'full' || github.event.inputs.setup_type == 'monitoring-only'
    
    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸ“Š Create Monitoring Configuration
        run: |
          mkdir -p monitoring-setup/{charts,configs,dashboards}

      - name: ðŸ“ˆ Prometheus Configuration
        run: |
          cat > monitoring-setup/charts/prometheus-values.yaml << 'EOF'
          server:
            enabled: true
            persistentVolume:
              enabled: true
              size: 10Gi
              storageClass: local-path
            resources:
              requests:
                memory: 1Gi
                cpu: 500m
              limits:
                memory: 2Gi
                cpu: 1000m
            retention: 15d
            global:
              scrape_interval: 15s
              evaluation_interval: 15s

          alertmanager:
            enabled: true
            persistentVolume:
              enabled: true
              size: 2Gi
              storageClass: local-path

          nodeExporter:
            enabled: true

          kubeStateMetrics:
            enabled: true

          pushgateway:
            enabled: true
          EOF

      - name: ðŸ“Š Grafana Configuration
        run: |
          cat > monitoring-setup/charts/grafana-values.yaml << 'EOF'
          admin:
            password: "admin123"
          persistence:
            enabled: true
            size: 5Gi
            storageClass: local-path
          resources:
            requests:
              memory: 512Mi
              cpu: 250m
            limits:
              memory: 1Gi
              cpu: 500m
          service:
            type: LoadBalancer
          datasources:
            datasources.yaml:
              apiVersion: 1
              datasources:
                - name: Prometheus
                  type: prometheus
                  url: http://prometheus-server.market-intel.svc.cluster.local
                  access: proxy
                  isDefault: true
          dashboardProviders:
            dashboardproviders.yaml:
              apiVersion: 1
              providers:
                - name: 'default'
                  orgId: 1
                  folder: ''
                  type: file
                  disableDeletion: false
                  updateIntervalSeconds: 10
                  allowUiUpdates: true
                  options:
                    path: /var/lib/grafana/dashboards/default
          EOF

      - name: ðŸ“ Loki Configuration
        run: |
          cat > monitoring-setup/charts/loki-values.yaml << 'EOF'
          loki:
            auth_enabled: false
            commonConfig:
              replication_factor: 1
            storage:
              type: 'filesystem'
              filesystem:
                chunks_directory: /loki/chunks
                rules_directory: /loki/rules
              boltdb_shipper:
                shared_store: filesystem
                cache_dir: /loki/boltdb-cache
            schema_config:
              configs:
                - from: 2020-10-24
                  store: boltdb-shipper
                  object_store: filesystem
                  schema: v11
                  index:
                    prefix: index_
                    period: 24h
            limits_config:
              enforce_metric_name: false
              reject_old_samples: true
              reject_old_samples_max_age: 168h
            chunk_store_config:
              max_look_back_period: 0s
            table_manager:
              retention_deletes_enabled: false
              retention_period: 0s
          singleBinary:
            replicas: 1
            resources:
              requests:
                memory: 512Mi
                cpu: 250m
              limits:
                memory: 1Gi
                cpu: 500m
          persistence:
            enabled: true
            size: 10Gi
            storageClass: local-path
          EOF

      - name: ðŸ“Š Monitoring Deployment Script
        run: |
          cat > monitoring-setup/scripts/deploy-monitoring.sh << 'EOF'
          #!/bin/bash
          set -e

          echo "ðŸ“Š Deploying monitoring stack..."

          # Create namespace
          kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -

          # Add repositories
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo add grafana https://grafana.github.io/helm-charts
          helm repo update

          # Install Prometheus
          helm install prometheus prometheus-community/kube-prometheus-stack \
            --namespace monitoring \
            --values prometheus-values.yaml \
            --wait

          # Install Grafana
          helm install grafana grafana/grafana \
            --namespace monitoring \
            --values grafana-values.yaml \
            --wait

          # Install Loki
          helm install loki grafana/loki-stack \
            --namespace monitoring \
            --values loki-values.yaml \
            --wait

          # Port forward for testing
          echo "ðŸ“Š Setting up port forwarding..."
          kubectl port-forward -n monitoring svc/prometheus-server 9090:80 &
          kubectl port-forward -n monitoring svc/grafana 3000:3000 &

          echo "âœ… Monitoring stack deployed successfully!"
          echo "ðŸ“Š Grafana: http://localhost:3000 (admin/admin123)"
          echo "ðŸ“ˆ Prometheus: http://localhost:9090"
          EOF

          chmod +x monitoring-setup/scripts/deploy-monitoring.sh

      - name: ðŸ“¤ Upload Monitoring Setup
        uses: actions/upload-artifact@v4
        with:
          name: monitoring-setup
          path: monitoring-setup/
          retention-days: 30

  # ===== KEDA & CILIUM SETUP =====
  setup-scaling-network:
    name: âš¡ Setup KEDA & Cilium
    runs-on: ubuntu-latest
    if: github.event.inputs.setup_type == 'full'
    
    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: âš¡ Create Scaling Configuration
        run: |
          mkdir -p scaling-setup/{charts,configs}

      - name: ðŸ”„ KEDA Configuration
        run: |
          cat > scaling-setup/charts/keda-values.yaml << 'EOF'
          metricsServer:
            securityContext:
              runAsNonRoot: true
            resources:
              requests:
                cpu: 10m
                memory: 64Mi
              limits:
                cpu: 100m
                memory: 256Mi
          webhooks:
            namespace: market-intel
          EOF

      - name: ðŸ”— Cilium Configuration
        run: |
          cat > scaling-setup/charts/cilium-values.yaml << 'EOF'
          kubeProxyReplacement: true
          enableHubble: true
          hubble:
            enabled: true
            metrics:
              enabled:
                - dns
                - drop
                - tcp
                - flow
                - port-distribution
                - icmp
            ui:
              enabled: true
              service:
                type: LoadBalancer
          operator:
            prometheus:
              enabled: true
          cni:
            exclusive: false
          ipam:
            mode: kubernetes
          tunnel: disabled
          bpf:
            masquerade: true
          EOF

      - name: âš¡ Scaling Deployment Script
        run: |
          cat > scaling-setup/scripts/deploy-scaling.sh << 'EOF'
          #!/bin/bash
          set -e

          echo "âš¡ Deploying KEDA and Cilium..."

          # Install KEDA
          helm repo add kedacore https://kedacore.github.io/charts
          helm repo update
          helm install keda kedacore/keda \
            --namespace keda \
            --create-namespace \
            --values keda-values.yaml

          # Install Cilium
          helm repo add cilium https://helm.cilium.io/
          helm repo update
          helm install cilium cilium/cilium \
            --namespace kube-system \
            --values cilium-values.yaml

          echo "âœ… KEDA and Cilium deployed successfully!"
          EOF

          chmod +x scaling-setup/scripts/deploy-scaling.sh

      - name: ðŸ“¤ Upload Scaling Setup
        uses: actions/upload-artifact@v4
        with:
          name: scaling-setup
          path: scaling-setup/
          retention-days: 30

  # ===== COMPLETE DEPLOYMENT SCRIPT =====
  create-complete-deployment:
    name: ðŸš€ Create Complete Deployment Script
    runs-on: ubuntu-latest
    needs: [setup-k3s-orchestrator, setup-redpanda-broker, setup-databases, setup-monitoring, setup-scaling-network]
    if: always()
    
    steps:
      - name: ðŸ“¥ Download All Artifacts
        uses: actions/download-artifact@v4
        with:
          path: all-setup/

      - name: ðŸš€ Create Master Deployment Script
        run: |
          cat > all-setup/deploy-enterprise.sh << 'EOF'
          #!/bin/bash
          set -e

          echo "ðŸš€ Deploying Enterprise Kubernetes Environment..."

          # System update
          echo "ðŸ”„ Updating system..."
          sudo apt update && sudo apt upgrade -y

          # Install K3s
          echo "ðŸŽ¯ Installing K3s..."
          ./k3s-orchestrator/scripts/install-k3s.sh

          # Setup Helm
          echo "ðŸ“¦ Setting up Helm..."
          ./k3s-orchestrator/scripts/setup-helm.sh

          # Deploy databases
          echo "ðŸ—„ï¸ Deploying databases..."
          cd databases-setup
          ./scripts/deploy-databases.sh
          cd ..

          # Deploy Redpanda
          echo "ðŸ“¨ Deploying Redpanda..."
          cd redpanda-setup
          ./scripts/deploy-redpanda.sh
          cd ..

          # Deploy monitoring
          echo "ðŸ“Š Deploying monitoring..."
          cd monitoring-setup
          ./scripts/deploy-monitoring.sh
          cd ..

          # Deploy scaling tools
          echo "âš¡ Deploying KEDA and Cilium..."
          cd scaling-setup
          ./scripts/deploy-scaling.sh
          cd ..

          # Verify deployment
          echo "âœ… Verifying deployment..."
          kubectl get nodes
          kubectl get pods --all-namespaces
          kubectl get services --all-namespaces

          echo "ðŸŽ‰ Enterprise Kubernetes environment deployed successfully!"
          echo ""
          echo "ðŸŒ Access URLs:"
          echo "  - Grafana: http://localhost:3000 (admin/admin123)"
          echo "  - Prometheus: http://localhost:9090"
          echo "  - K3s Dashboard: kubectl top nodes"
          echo ""
          echo "ðŸ“Š Check status with:"
          echo "  - kubectl get pods -n market-intel"
          echo "  - kubectl get services -n market-intel"
          EOF

          chmod +x all-setup/deploy-enterprise.sh

      - name: ðŸ“‹ Create README
        run: |
          cat > all-setup/README.md << 'EOF'
          # ðŸš€ Enterprise Kubernetes Environment

          ## ðŸŽ¯ Architecture Overview

          This setup creates a complete enterprise-grade Kubernetes environment with:

          ### 1. ðŸŽ¯ Orchestrator (K3s)
          - Lightweight Kubernetes distribution
          - Single-node cluster
          - Perfect for edge computing
          - Built-in load balancer

          ### 2. ðŸ“¨ Message Broker (Redpanda)
          - Kafka-compatible streaming platform
          - No Java dependency
          - Ultra-low latency
          - Auto-scaling capabilities

          ### 3. ðŸ—„ï¸ Databases
          - **TimescaleDB**: PostgreSQL + time-series extensions
          - **Qdrant**: Vector database for AI agents
          - **Redis**: High-speed caching layer

          ### 4. ðŸ“Š Monitoring (Observability)
          - **Prometheus**: Metrics collection
          - **Grafana**: Visualization dashboards
          - **Loki**: Log aggregation

          ### 5. âš¡ Performance & Scaling
          - **KEDA**: Event-driven auto-scaling
          - **Cilium**: eBPF-based networking
          - Zero-latency communication

          ## ðŸš€ Quick Deployment

          ```bash
          # Download all artifacts
          # Extract to your server
          
          # Run complete deployment
          ./deploy-enterprise.sh
          ```

          ## ðŸŒ Service Access

          | Service | URL | Credentials |
          |---------|-----|-------------|
          | Grafana | http://localhost:3000 | admin/admin123 |
          | Prometheus | http://localhost:9090 | - |
          | TimescaleDB | localhost:5432 | postgres/marketintel123 |
          | Qdrant | localhost:6333 | - |
          | Redis | localhost:6379 | -/redis123 |
          | Redpanda | localhost:9092 | - |

          ## ðŸ“Š Monitoring

          ### Grafana Dashboards
          - System Overview
          - Database Performance
          - Message Broker Metrics
          - Application Performance

          ### Prometheus Metrics
          - Resource utilization
          - Database connections
          - Message throughput
          - Network latency

          ## âš¡ Auto-Scaling

          KEDA will automatically scale based on:
          - Message queue length
          - CPU utilization
          - Memory usage
          - Custom metrics

          ## ðŸ”§ Management

          ```bash
          # Check cluster status
          kubectl get nodes
          kubectl get pods --all-namespaces

          # Monitor resources
          kubectl top nodes
          kubectl top pods -n market-intel

          # Scale applications
          kubectl scale deployment app-name --replicas=3 -n market-intel

          # View logs
          kubectl logs -f deployment/app-name -n market-intel
          ```

          ## ðŸ›¡ï¸ Security

          - Network policies enforced by Cilium
          - eBPF-based filtering
          - Zero-trust architecture
          - Encrypted communications

          ## ðŸ”„ Updates

          ```bash
          # Update K3s
          curl -sfL https://get.k3s.io | sh -s - --write-kubeconfig-mode 644

          # Update Helm charts
          helm repo update
          helm upgrade <release> <repo/chart> -n <namespace>
          ```
          EOF

      - name: ðŸ“¤ Upload Complete Setup
        uses: actions/upload-artifact@v4
        with:
          name: enterprise-kubernetes-setup
          path: all-setup/
          retention-days: 30
