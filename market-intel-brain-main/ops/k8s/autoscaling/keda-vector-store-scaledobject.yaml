---
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: vector-store-scaledobject
  namespace: market-intel-brain
  labels:
    app: market-intel-brain
    component: vector-store
    autoscaling: keda
  annotations:
    scaledobject.keda.sh/transfer-hpa-owner: "true"
    prometheus.io/scrape: "true"
    prometheus.io/port: "9090"
    prometheus.io/path: "/metrics"
spec:
  scaleTargetRef:
    name: vector-store-deployment
    service: vector-store-service
  pollingInterval: 15         # Default: 30 seconds
  cooldownPeriod: 120         # Default: 300 seconds
  idleReplicaCount: 1         # Minimum replicas when idle
  minReplicaCount: 1          # Minimum replicas
  maxReplicaCount: 15         # Maximum replicas for AI/ML workloads
  fallback:                   # Fallback configuration
    failureThreshold: 3       # Number of consecutive failed scalings before fallback
    replicas: 1               # Fallback replica count
  advanced:
    horizontalPodAutoscalerConfig:
      behavior:
        scaleUp:
          stabilizationWindowSeconds: 0      # Immediate scale-up for AI workloads
          policies:
            - type: Pods
              value: 3                       # Scale up by 3 pods at once
              periodSeconds: 20              # Every 20 seconds
            - type: Percent
              value: 300                     # Scale up by 300% at once
              periodSeconds: 30              # Every 30 seconds
          selectPolicy: Max                  # Use the maximum change
        scaleDown:
          stabilizationWindowSeconds: 300    # Conservative scale-down (5 minutes)
          policies:
            - type: Pods
              value: 1                       # Scale down by 1 pod at once
              periodSeconds: 90              # Every 1.5 minutes
            - type: Percent
              value: 25                      # Scale down by 25% at once
              periodSeconds: 180             # Every 3 minutes
          selectPolicy: Min                  # Use the minimum change
  triggers:
    # Vector Search Operations Trigger (Primary)
    - type: prometheus
      metadata:
        serverAddress: http://prometheus-service.market-intel-brain-observability.svc.cluster.local:9090
        query: |
          sum(
            rate(
              vector_store_operations_total{
                service="rust-engine",
                namespace="market-intel-brain",
                operation_type="search"
              }[2m]
            )
          )
        threshold: "200"                    # Scale when vector searches per second > 200
        activationThreshold: "50"            # Activate when vector searches per second > 50
        metricName: "vector_searches_per_second"
    # Vector Upsert Operations Trigger
    - type: prometheus
      metadata:
        serverAddress: http://prometheus-service.market-intel-brain-observability.svc.cluster.local:9090
        query: |
          sum(
            rate(
              vector_store_operations_total{
                service="rust-engine",
                namespace="market-intel-brain",
                operation_type="upsert"
              }[2m]
            )
          )
        threshold: "100"                    # Scale when vector upserts per second > 100
        activationThreshold: "20"            # Activate when vector upserts per second > 20
        metricName: "vector_upserts_per_second"
    # Qdrant Connection Pool Trigger
    - type: prometheus
      metadata:
        serverAddress: http://prometheus-service.market-intel-brain-observability.svc.cluster.local:9090
        query: |
          qdrant_active_connections{
            service="vector-store",
            namespace="market-intel-brain"
          }
        threshold: "500"                    # Scale when active Qdrant connections > 500
        activationThreshold: "100"            # Activate when active Qdrant connections > 100
        metricName: "qdrant_active_connections"
    # AI/ML Request Rate Trigger
    - type: prometheus
      metadata:
        serverAddress: http://prometheus-service.market-intel-brain-observability.svc.cluster.local:9090
        query: |
          sum(
            rate(
              grpc_server_started_total{
                service="rust-engine",
                method=~".*(AnalyzeMarketData|GetPredictiveInsights).*",
                namespace="market-intel-brain"
              }[2m]
            )
          )
        threshold: "50"                     # Scale when AI/ML requests per second > 50
        activationThreshold: "10"            # Activate when AI/ML requests per second > 10
        metricName: "ai_ml_requests_per_second"
    # Vector Store Search Latency Trigger
    - type: prometheus
      metadata:
        serverAddress: http://prometheus-service.market-intel-brain-observability.svc.cluster.local:9090
        query: |
          histogram_quantile(0.95,
            sum(
              rate(
                vector_store_search_duration_seconds_bucket{
                  service="rust-engine",
                  namespace="market-intel-brain"
                }[2m]
              )
            ) by (le)
          )
        threshold: "0.1"                     # Scale when P95 search latency > 100ms
        activationThreshold: "0.05"           # Activate when P95 search latency > 50ms
        metricName: "vector_search_latency_p95"
    # CPU Usage Trigger (Secondary)
    - type: prometheus
      metadata:
        serverAddress: http://prometheus-service.market-intel-brain-observability.svc.cluster.local:9090
        query: |
          sum(
            rate(
              container_cpu_usage_seconds_total{
                pod=~"vector-store-.*",
                namespace="market-intel-brain",
                container!="POD",
                container!=""
              }[2m]
            )
          ) / sum(
            kube_pod_container_resource_requests{
                pod=~"vector-store-.*",
                namespace="market-intel-brain",
                resource="cpu"
              }
          ) * 100
        threshold: "80"                     # Scale when CPU usage > 80%
        activationThreshold: "60"            # Activate when CPU usage > 60%
        metricName: "cpu_usage_percent"
    # Memory Usage Trigger (Secondary)
    - type: prometheus
      metadata:
        serverAddress: http://prometheus-service.market-intel-brain-observability.svc.cluster.local:9090
        query: |
          sum(
            container_memory_working_set_bytes{
              pod=~"vector-store-.*",
              namespace="market-intel-brain",
              container!="POD",
              container!=""
            }
          ) / sum(
            kube_pod_container_resource_requests{
                pod=~"vector-store-.*",
                namespace="market-intel-brain",
                resource="memory"
            }
          ) * 100
        threshold: "85"                     # Scale when memory usage > 85%
        activationThreshold: "65"            # Activate when memory usage > 65%
        metricName: "memory_usage_percent"
    # Qdrant Index Size Trigger
    - type: prometheus
      metadata:
        serverAddress: http://prometheus-service.market-intel-brain-observability.svc.cluster.local:9090
        query: |
          qdrant_collection_size_bytes{
            collection="market_data_vectors",
            namespace="market-intel-brain"
          } / 1024 / 1024 / 1024  # Convert to GB
        threshold: "50"                     # Scale when collection size > 50GB
        activationThreshold: "20"            # Activate when collection size > 20GB
        metricName: "qdrant_collection_size_gb"
---
# KEDA Authentication for Prometheus
apiVersion: v1
kind: Secret
metadata:
  name: keda-vector-store-prometheus-secret
  namespace: market-intel-brain
type: Opaque
data:
  # Base64 encoded empty string (no auth needed for internal Prometheus)
  bearerToken: ""
---
# ServiceMonitor for Vector Store Metrics
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: vector-store-servicemonitor
  namespace: market-intel-brain
  labels:
    app: market-intel-brain
    component: vector-store
    monitoring: prometheus
spec:
  selector:
    matchLabels:
      app: market-intel-brain
      component: vector-store
  endpoints:
    - port: metrics
      path: /metrics
      interval: 30s
      scrapeTimeout: 10s
      honorLabels: true
---
# PrometheusRule for Vector Store Autoscaling Metrics
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: vector-store-autoscaling-rules
  namespace: market-intel-brain
  labels:
    app: market-intel-brain
    component: vector-store
    autoscaling: keda
spec:
  groups:
    - name: vector-store-autoscaling
      rules:
        # Vector Searches Per Second
        - record: vector_store:searches_per_second:rate2m
          expr: |
            sum(
              rate(
                vector_store_operations_total{
                  service="rust-engine",
                  namespace="market-intel-brain",
                  operation_type="search"
                }[2m]
              )
            )
          labels:
            component: vector-store
            autoscaling_metric: "searches_rps"
        # Vector Upserts Per Second
        - record: vector_store:upserts_per_second:rate2m
          expr: |
            sum(
              rate(
                vector_store_operations_total{
                  service="rust-engine",
                  namespace="market-intel-brain",
                  operation_type="upsert"
                }[2m]
              )
            )
          labels:
            component: vector-store
            autoscaling_metric: "upserts_rps"
        # Qdrant Active Connections
        - record: vector_store:qdrant_active_connections
          expr: |
            qdrant_active_connections{
              service="vector-store",
              namespace="market-intel-brain"
            }
          labels:
            component: vector-store
            autoscaling_metric: "qdrant_connections"
        # AI/ML Requests Per Second
        - record: vector_store:ai_ml_requests_per_second:rate2m
          expr: |
            sum(
              rate(
                grpc_server_started_total{
                  service="rust-engine",
                  method=~".*(AnalyzeMarketData|GetPredictiveInsights).*",
                  namespace="market-intel-brain"
                }[2m]
              )
            )
          labels:
            component: vector-store
            autoscaling_metric: "ai_ml_rps"
        # P95 Vector Search Latency
        - record: vector_store:search_latency_p95:quantile
          expr: |
            histogram_quantile(0.95,
              sum(
                rate(
                  vector_store_search_duration_seconds_bucket{
                    service="rust-engine",
                    namespace="market-intel-brain"
                  }[2m]
                )
              ) by (le)
            )
          labels:
            component: vector-store
            autoscaling_metric: "search_latency_p95"
        # CPU Usage Percentage
        - record: vector_store:cpu_usage_percent:rate2m
          expr: |
            sum(
              rate(
                container_cpu_usage_seconds_total{
                  pod=~"vector-store-.*",
                  namespace="market-intel-brain",
                  container!="POD",
                  container!=""
                }[2m]
              )
            ) / sum(
              kube_pod_container_resource_requests{
                  pod=~"vector-store-.*",
                  namespace="market-intel-brain",
                  resource="cpu"
                }
            ) * 100
          labels:
            component: vector-store
            autoscaling_metric: "cpu_usage"
        # Memory Usage Percentage
        - record: vector_store:memory_usage_percent
          expr: |
            sum(
              container_memory_working_set_bytes{
                pod=~"vector-store-.*",
                namespace="market-intel-brain",
                container!="POD",
                container!=""
              }
            ) / sum(
              kube_pod_container_resource_requests{
                  pod=~"vector-store-.*",
                  namespace="market-intel-brain",
                  resource="memory"
                }
            ) * 100
          labels:
            component: vector-store
            autoscaling_metric: "memory_usage"
        # Qdrant Collection Size in GB
        - record: vector_store:qdrant_collection_size_gb
          expr: |
            qdrant_collection_size_bytes{
              collection="market_data_vectors",
              namespace="market-intel-brain"
            } / 1024 / 1024 / 1024
          labels:
            component: vector-store
            autoscaling_metric: "collection_size_gb"
