"""
MAIFA v3 Classifier Service - Event and Data Classification
Classifies market events, news, and data into meaningful categories
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import re
import json
from enum import Enum

from models.schemas import Priority

class EventType(Enum):
    """Event types for classification"""
    PRICE_MOVEMENT = "price_movement"
    NEWS_EVENT = "news_event"
    TRADING_SIGNAL = "trading_signal"
    EARNINGS_REPORT = "earnings_report"
    ECONOMIC_INDICATOR = "economic_indicator"
    MARKET_SENTIMENT = "market_sentiment"
    REGULATORY_CHANGE = "regulatory_change"
    TECHNICAL_ANALYSIS = "technical_analysis"
    COMPANY_SPECIFIC = "company_specific"
    MACRO_ECONOMIC = "macro_economic"

class DataCategory(Enum):
    """Data categories for classification"""
    REAL_TIME = "real_time"
    HISTORICAL = "historical"
    FUNDAMENTAL = "fundamental"
    TECHNICAL = "technical"
    SENTIMENT = "sentiment"
    ECONOMIC = "economic"
    NEWS = "news"
    SOCIAL_MEDIA = "social_media"

class ClassifierService:
    """
    MAIFA v3 Classifier Service - Intelligent data and event classification
    
    Provides:
    - Event type classification
    - Data categorization
    - Priority assignment
    - Relevance scoring
    - Multi-label classification
    """
    
    def __init__(self):
        self.logger = logging.getLogger("ClassifierService")
        self._event_patterns = self._initialize_event_patterns()
        self._category_keywords = self._initialize_category_keywords()
        self._priority_rules = self._initialize_priority_rules()
        self._classification_cache = {}
        
    def _initialize_event_patterns(self) -> Dict[EventType, List[Dict[str, Any]]]:
        """Initialize pattern matching rules for event types"""
        return {
            EventType.PRICE_MOVEMENT: [
                {"pattern": r"(price|stock|shares?) (is|are|jumped|surged|dropped|fell|rose)", "weight": 0.9},
                {"pattern": r"\$[0-9]+\.?[0-9]*", "weight": 0.7},  # Price mentions
                {"pattern": r"(up|down) [0-9]+%", "weight": 0.8},
                {"pattern": r"(market|index) (gains|loses|rises|falls)", "weight": 0.8}
            ],
            EventType.NEWS_EVENT: [
                {"pattern": r"(according to|reports say|announced|declared)", "weight": 0.8},
                {"pattern": r"(breaking|latest|recent) news", "weight": 0.7},
                {"pattern": r"(press release|statement|announcement)", "weight": 0.9}
            ],
            EventType.TRADING_SIGNAL: [
                {"pattern": r"(buy|sell|hold) (recommendation|rating|signal)", "weight": 0.9},
                {"pattern": r"(bullish|bearish) (signal|outlook|view)", "weight": 0.8},
                {"pattern": r"(upgrade|downgrade) (to|from)", "weight": 0.9}
            ],
            EventType.EARNINGS_REPORT: [
                {"pattern": r"(earnings|EPS|revenue) (beat|miss|meet) (expectations|estimates)", "weight": 0.9},
                {"pattern": r"(quarterly|Q[1-4]) (results|earnings|report)", "weight": 0.8},
                {"pattern": r"(year over year|YoY) (growth|decline)", "weight": 0.7}
            ],
            EventType.ECONOMIC_INDICATOR: [
                {"pattern": r"(GDP|inflation|unemployment|interest rates)", "weight": 0.9},
                {"pattern": r"(Federal Reserve|Fed) (decision|announcement|meeting)", "weight": 0.8},
                {"pattern": r"(consumer price index|CPI|producer price index|PPI)", "weight": 0.8}
            ],
            EventType.MARKET_SENTIMENT: [
                {"pattern": r"(investor|market) (sentiment|mood|confidence)", "weight": 0.8},
                {"pattern": r"(fear|greed) (index|gauge|meter)", "weight": 0.9},
                {"pattern": r"(bullish|bearish) (sentiment|outlook)", "weight": 0.7}
            ],
            EventType.REGULATORY_CHANGE: [
                {"pattern": r"(SEC|FDA|EPA|regulation|regulatory)", "weight": 0.9},
                {"pattern": r"(approval|rejection|ban|restriction)", "weight": 0.8},
                {"pattern": r"(compliance|violation|investigation)", "weight": 0.7}
            ],
            EventType.TECHNICAL_ANALYSIS: [
                {"pattern": r"(support|resistance) (level|line)", "weight": 0.8},
                {"pattern": r"(moving average|MA|EMA|SMA)", "weight": 0.9},
                {"pattern": r"(RSI|MACD|Bollinger|Fibonacci)", "weight": 0.9}
            ],
            EventType.COMPANY_SPECIFIC: [
                {"pattern": r"(CEO|CFO|executive|management)", "weight": 0.7},
                {"pattern": r"(merger|acquisition|M&A|takeover)", "weight": 0.9},
                {"pattern": r"(product launch|innovation|patent)", "weight": 0.8}
            ],
            EventType.MACRO_ECONOMIC: [
                {"pattern": r"(recession|recovery|expansion|contraction)", "weight": 0.9},
                {"pattern": r"(trade war|tariff|sanction|embargo)", "weight": 0.8},
                {"pattern": r"(global|world) (economy|market)", "weight": 0.7}
            ]
        }
    
    def _initialize_category_keywords(self) -> Dict[DataCategory, List[str]]:
        """Initialize keyword mappings for data categories"""
        return {
            DataCategory.REAL_TIME: ["live", "real-time", "streaming", "current", "now"],
            DataCategory.HISTORICAL: ["historical", "past", "previous", "yesterday", "last week"],
            DataCategory.FUNDAMENTAL: ["revenue", "earnings", "P/E", "book value", "dividend"],
            DataCategory.TECHNICAL: ["chart", "indicator", "pattern", "trend", "support", "resistance"],
            DataCategory.SENTIMENT: ["sentiment", "mood", "feeling", "opinion", "bullish", "bearish"],
            DataCategory.ECONOMIC: ["GDP", "inflation", "unemployment", "interest rates", "economy"],
            DataCategory.NEWS: ["news", "article", "report", "story", "breaking", "announcement"],
            DataCategory.SOCIAL_MEDIA: ["twitter", "reddit", "social", "post", "tweet", "comment"]
        }
    
    def _initialize_priority_rules(self) -> Dict[str, Dict[str, Any]]:
        """Initialize priority assignment rules"""
        return {
            "high_priority_keywords": {
                "keywords": ["breaking", "urgent", "critical", "alert", "crash", "surge"],
                "priority": Priority.HIGH,
                "boost": 0.3
            },
            "medium_priority_keywords": {
                "keywords": ["report", "announcement", "update", "change", "movement"],
                "priority": Priority.MEDIUM,
                "boost": 0.1
            },
            "low_priority_keywords": {
                "keywords": ["summary", "review", "analysis", "commentary"],
                "priority": Priority.LOW,
                "boost": -0.1
            },
            "critical_events": {
                "event_types": [EventType.EARNINGS_REPORT, EventType.REGULATORY_CHANGE],
                "priority": Priority.CRITICAL,
                "boost": 0.4
            }
        }
    
    async def classify_event(self, text: str, metadata: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Classify text into event types with confidence scores
        
        Args:
            text: Text to classify
            metadata: Optional metadata for context
            
        Returns:
            Classification results with event types and confidence scores
        """
        try:
            self.logger.debug("Classifying event from text")
            
            text_lower = text.lower()
            event_scores = {}
            
            # Score each event type based on pattern matching
            for event_type, patterns in self._event_patterns.items():
                score = 0.0
                matches = []
                
                for pattern_info in patterns:
                    pattern = pattern_info["pattern"]
                    weight = pattern_info["weight"]
                    
                    pattern_matches = re.findall(pattern, text_lower)
                    if pattern_matches:
                        pattern_score = len(pattern_matches) * weight
                        score += pattern_score
                        matches.extend(pattern_matches)
                
                if score > 0:
                    event_scores[event_type] = {
                        "score": score,
                        "matches": matches,
                        "confidence": min(score / 2.0, 1.0)  # Normalize to 0-1
                    }
            
            # Sort by score
            sorted_events = sorted(
                event_scores.items(),
                key=lambda x: x[1]["score"],
                reverse=True
            )
            
            # Prepare results
            if sorted_events:
                primary_event = sorted_events[0][0]
                primary_confidence = sorted_events[0][1]["confidence"]
                
                # Multi-label classification (events can have multiple types)
                secondary_events = [
                    {
                        "event_type": event_type.value,
                        "confidence": data["confidence"]
                    }
                    for event_type, data in sorted_events[1:3]  # Top 3 events
                    if data["confidence"] > 0.3
                ]
                
                classification_result = {
                    "primary_event": {
                        "event_type": primary_event.value,
                        "confidence": primary_confidence,
                        "matches": sorted_events[0][1]["matches"]
                    },
                    "secondary_events": secondary_events,
                    "all_scores": {
                        event_type.value: data["confidence"]
                        for event_type, data in event_scores.items()
                    },
                    "classification_timestamp": datetime.now().isoformat()
                }
            else:
                classification_result = {
                    "primary_event": {
                        "event_type": EventType.NEWS_EVENT.value,  # Default
                        "confidence": 0.1,
                        "matches": []
                    },
                    "secondary_events": [],
                    "all_scores": {},
                    "classification_timestamp": datetime.now().isoformat()
                }
            
            self.logger.debug(f"Event classification completed: {classification_result['primary_event']['event_type']}")
            return classification_result
            
        except Exception as e:
            self.logger.error(f"Event classification failed: {e}")
            return {
                "primary_event": {"event_type": EventType.NEWS_EVENT.value, "confidence": 0.0},
                "error": str(e)
            }
    
    async def classify_data(self, 
                           data: Dict[str, Any], 
                           source: str = "unknown") -> Dict[str, Any]:
        """
        Classify data into categories
        
        Args:
            data: Data to classify
            source: Data source identifier
            
        Returns:
            Data classification results
        """
        try:
            self.logger.debug(f"Classifying data from {source}")
            
            category_scores = {}
            text_content = ""
            
            # Extract text content from data
            if "text" in data:
                text_content = data["text"]
            elif "title" in data:
                text_content = data["title"]
            elif "content" in data:
                text_content = data["content"]
            
            text_content = text_content.lower()
            
            # Score each category based on keyword matching
            for category, keywords in self._category_keywords.items():
                score = 0.0
                matched_keywords = []
                
                for keyword in keywords:
                    if keyword in text_content:
                        keyword_count = text_content.count(keyword)
                        score += keyword_count
                        matched_keywords.extend([keyword] * keyword_count)
                
                if score > 0:
                    category_scores[category] = {
                        "score": score,
                        "matched_keywords": matched_keywords,
                        "confidence": min(score / 5.0, 1.0)  # Normalize to 0-1
                    }
            
            # Determine primary category
            if category_scores:
                primary_category = max(category_scores.items(), key=lambda x: x[1]["score"])
                
                classification_result = {
                    "primary_category": {
                        "category": primary_category[0].value,
                        "confidence": primary_category[1]["confidence"],
                        "matched_keywords": primary_category[1]["matched_keywords"]
                    },
                    "all_categories": {
                        category.value: data["confidence"]
                        for category, data in category_scores.items()
                    },
                    "data_source": source,
                    "classification_timestamp": datetime.now().isoformat()
                }
            else:
                classification_result = {
                    "primary_category": {
                        "category": DataCategory.NEWS.value,  # Default
                        "confidence": 0.1,
                        "matched_keywords": []
                    },
                    "all_categories": {},
                    "data_source": source,
                    "classification_timestamp": datetime.now().isoformat()
                }
            
            self.logger.debug(f"Data classification completed: {classification_result['primary_category']['category']}")
            return classification_result
            
        except Exception as e:
            self.logger.error(f"Data classification failed: {e}")
            return {
                "primary_category": {"category": DataCategory.NEWS.value, "confidence": 0.0},
                "error": str(e)
            }
    
    async def assign_priority(self, 
                            classification_result: Dict[str, Any],
                            text: str,
                            metadata: Optional[Dict[str, Any]] = None) -> Priority:
        """
        Assign priority based on classification and content
        
        Args:
            classification_result: Event classification result
            text: Original text
            metadata: Optional metadata
            
        Returns:
            Assigned priority
        """
        try:
            text_lower = text.lower()
            base_priority = Priority.MEDIUM
            priority_boost = 0.0
            
            # Check for high priority keywords
            high_keywords = self._priority_rules["high_priority_keywords"]["keywords"]
            high_boost = self._priority_rules["high_priority_keywords"]["boost"]
            
            for keyword in high_keywords:
                if keyword in text_lower:
                    priority_boost += high_boost
            
            # Check for critical event types
            critical_events = self._priority_rules["critical_events"]["event_types"]
            critical_boost = self._priority_rules["critical_events"]["boost"]
            
            primary_event = classification_result.get("primary_event", {}).get("event_type", "")
            
            try:
                event_enum = EventType(primary_event)
                if event_enum in critical_events:
                    priority_boost += critical_boost
            except ValueError:
                pass  # Event type not recognized
            
            # Check for medium priority keywords
            medium_keywords = self._priority_rules["medium_priority_keywords"]["keywords"]
            medium_boost = self._priority_rules["medium_priority_keywords"]["boost"]
            
            for keyword in medium_keywords:
                if keyword in text_lower:
                    priority_boost += medium_boost
            
            # Check for low priority keywords
            low_keywords = self._priority_rules["low_priority_keywords"]["keywords"]
            low_boost = self._priority_rules["low_priority_keywords"]["boost"]
            
            for keyword in low_keywords:
                if keyword in text_lower:
                    priority_boost += low_boost
            
            # Determine final priority based on boost
            if priority_boost >= 0.4:
                return Priority.CRITICAL
            elif priority_boost >= 0.2:
                return Priority.HIGH
            elif priority_boost <= -0.1:
                return Priority.LOW
            else:
                return Priority.MEDIUM
                
        except Exception as e:
            self.logger.error(f"Priority assignment failed: {e}")
            return Priority.MEDIUM
    
    async def calculate_relevance(self, 
                                text: str,
                                symbols: List[str],
                                keywords: List[str]) -> float:
        """
        Calculate relevance score for text based on symbols and keywords
        
        Args:
            text: Text to analyze
            symbols: List of financial symbols
            keywords: List of relevant keywords
            
        Returns:
            Relevance score (0.0 to 1.0)
        """
        try:
            text_lower = text.lower()
            relevance_score = 0.0
            
            # Symbol relevance (higher weight)
            symbol_matches = 0
            for symbol in symbols:
                if symbol.lower() in text_lower:
                    symbol_matches += 1
            
            symbol_relevance = min(symbol_matches / len(symbols), 1.0) if symbols else 0.0
            relevance_score += symbol_relevance * 0.6
            
            # Keyword relevance
            keyword_matches = 0
            for keyword in keywords:
                if keyword.lower() in text_lower:
                    keyword_matches += 1
            
            keyword_relevance = min(keyword_matches / len(keywords), 1.0) if keywords else 0.0
            relevance_score += keyword_relevance * 0.4
            
            return min(relevance_score, 1.0)
            
        except Exception as e:
            self.logger.error(f"Relevance calculation failed: {e}")
            return 0.0
    
    async def batch_classify(self, 
                           texts: List[str],
                           metadata_list: Optional[List[Dict[str, Any]]] = None) -> List[Dict[str, Any]]:
        """Classify multiple texts in parallel"""
        if metadata_list is None:
            metadata_list = [None] * len(texts)
        elif len(metadata_list) != len(texts):
            metadata_list = [None] * len(texts)
        
        tasks = [
            self.classify_event(text, metadata)
            for text, metadata in zip(texts, metadata_list)
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Filter out exceptions
        valid_results = []
        for result in results:
            if isinstance(result, Exception):
                self.logger.error(f"Batch classification error: {result}")
                valid_results.append({
                    "primary_event": {"event_type": EventType.NEWS_EVENT.value, "confidence": 0.0},
                    "error": str(result)
                })
            else:
                valid_results.append(result)
        
        return valid_results
    
    async def get_classification_stats(self) -> Dict[str, Any]:
        """Get classifier service statistics"""
        return {
            "event_types_count": len(self._event_patterns),
            "data_categories_count": len(self._category_keywords),
            "priority_rules_count": len(self._priority_rules),
            "cache_size": len(self._classification_cache),
            "available_event_types": [event_type.value for event_type in EventType],
            "available_categories": [category.value for category in DataCategory]
        }


# Global classifier service instance
classifier_service = ClassifierService()
