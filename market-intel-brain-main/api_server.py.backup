"""
Market Intel Brain - FastAPI Entry Point

Professional web server that integrates all 19+ architectural layers
with live API endpoints, QoS management, and real-time monitoring.

Features:
- Unified data endpoint with dynamic adapter discovery
- QoS integration with priority-based task scheduling
- Background cache warming with low-priority tasks
- Comprehensive health monitoring and metrics
- Auto-discovery and registration of adapters
- Zero-trust security with encrypted credentials
- Professional Swagger documentation
"""

import asyncio
import logging
import time
from contextlib import asynccontextmanager
from datetime import datetime
from typing import Dict, Any, Optional, List

import redis.asyncio as redis
import httpx
from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field

# Import our 19+ architectural layers
from orchestrator.registry import AdapterRegistry
from services.data_ingestion.source_adapter.orchestrator.adapter_registry import get_adapter_registry
from adapters.binance_adapter import create_binance_adapter
from qos.scheduler import QoSScheduler, SchedulerConfig
from qos.priority import Priority, create_task
from security.settings import get_settings
from services.cache.tiered_cache_manager import TieredCacheManager
from finops.budget_firewall import get_firewall
from services.schemas.market_data import UnifiedMarketData

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("MarketIntelAPI")

# Global state for our integrated architecture
class GlobalState:
    """Global application state with all architectural components."""
    
    def __init__(self):
        self.redis_client: Optional[redis.Redis] = None
        self.http_session: Optional[httpx.AsyncClient] = None
        self.adapter_registry: Optional[AdapterRegistry] = None
        self.data_adapter_registry: Optional[Any] = None  # For data ingestion adapters
        self.qos_scheduler: Optional[QoSScheduler] = None
        self.cache_manager: Optional[TieredCacheManager] = None
        self.budget_firewall: Optional[Any] = None
        self.settings: Optional[Any] = None
        self.background_tasks: List[asyncio.Task] = []
        self._start_time = time.time()
        
    async def initialize(self):
        """Initialize all architectural components."""
        logger.info("ðŸš€ Initializing Market Intel Brain API...")
        
        # Load secure settings
        self.settings = get_settings()
        logger.info("âœ… Security settings loaded with zero-trust principles")
        
        # Initialize Redis client
        redis_url = self.settings.redis_url.get_secret_value()
        self.redis_client = redis.from_url(redis_url)
        await self.redis_client.ping()
        logger.info(f"âœ… Redis connected: {redis_url[:20]}...")
        
        # Initialize HTTP session
        self.http_session = httpx.AsyncClient(
            timeout=httpx.Timeout(30.0),
            limits=httpx.Limits(max_keepalive_connections=20, max_connections=100)
        )
        logger.info("âœ… HTTP session initialized")
        
        # Initialize adapter registries
        self.adapter_registry = AdapterRegistry()
        self.data_adapter_registry = get_adapter_registry(self.redis_client)
        logger.info("âœ… Adapter registries initialized")
        
        # Auto-discover and register adapters
        await self._discover_adapters()
        
        # Initialize QoS scheduler
        scheduler_config = SchedulerConfig(
            auto_start=True,
            enable_monitoring=True,
            monitoring_interval=5.0,
            max_low_priority_delay=10.0,
            low_priority_throttle_rate=0.1
        )
        self.qos_scheduler = QoSScheduler(scheduler_config)
        await self.qos_scheduler.start()
        logger.info("âœ… QoS scheduler started")
        
        # Initialize cache manager
        self.cache_manager = TieredCacheManager()
        await self.cache_manager.health_check()
        logger.info("âœ… Tiered cache manager initialized")
        
        # Initialize budget firewall
        self.budget_firewall = get_firewall()
        await self.budget_firewall.start()
        logger.info("âœ… Budget firewall started")
        
        # Start background workers
        await self._start_background_workers()
        
        logger.info("ðŸŽ‰ Market Intel Brain API fully initialized!")
    
    async def _discover_adapters(self):
        """Auto-discover and register adapters from adapters/ directory."""
        try:
            # Create Binance adapter (our concrete implementation)
            binance_adapter = await create_binance_adapter(self.redis_client)
            logger.info("âœ… Binance adapter created and registered")
            
            # The @register_adapter decorator automatically registers it
            # in the AdapterRegistry singleton
            
            # List all registered adapters
            registered_adapters = self.adapter_registry.list_adapters()
            logger.info(f"âœ… Discovered adapters: {registered_adapters}")
            
        except Exception as e:
            logger.error(f"âŒ Adapter discovery failed: {e}")
            raise
    
    async def _start_background_workers(self):
        """Start background workers for cache warming and maintenance."""
        # Background cache warming for popular symbols
        cache_warming_task = asyncio.create_task(self._cache_warming_worker())
        self.background_tasks.append(cache_warming_task)
        
        # Background health monitoring
        health_monitor_task = asyncio.create_task(self._health_monitoring_worker())
        self.background_tasks.append(health_monitor_task)
        
        logger.info("âœ… Background workers started")
    
    async def _cache_warming_worker(self):
        """Background worker to warm cache for popular symbols."""
        popular_symbols = ["BTCUSDT", "ETHUSDT", "BNBUSDT"]
        
        while True:
            try:
                for symbol in popular_symbols:
                    # Submit as low priority background task
                    await self.qos_scheduler.submit_background_task(
                        self._warm_symbol_cache,
                        symbol,
                        priority=Priority.LOW,
                        timeout=30.0
                    )
                
                # Wait 5 minutes before next cycle
                await asyncio.sleep(300)
                
            except Exception as e:
                logger.error(f"Cache warming error: {e}")
                await asyncio.sleep(60)  # Wait 1 minute on error
    
    async def _warm_symbol_cache(self, symbol: str):
        """Warm cache for a specific symbol."""
        try:
            if self.adapter_registry.is_registered("binance"):
                # This will use the adapter with full layer integration
                adapter = self.adapter_registry.create_instance("binance", redis_client=self.redis_client)
                await adapter.get_price(symbol)
                logger.debug(f"âœ… Cache warmed for {symbol}")
        except Exception as e:
            logger.debug(f"Cache warming failed for {symbol}: {e}")
    
    async def _health_monitoring_worker(self):
        """Background worker for health monitoring."""
        while True:
            try:
                # Perform health checks
                health_status = await self._get_comprehensive_health()
                
                # Cache health status
                if self.cache_manager:
                    await self.cache_manager.set(
                        "system_health",
                        health_status,
                        ttl=60,
                        namespace="monitoring"
                    )
                
                await asyncio.sleep(30)  # Check every 30 seconds
                
            except Exception as e:
                logger.error(f"Health monitoring error: {e}")
                await asyncio.sleep(60)
    
    async def _get_comprehensive_health(self) -> Dict[str, Any]:
        """Get comprehensive system health status."""
        health = {
            "timestamp": datetime.utcnow().isoformat(),
            "status": "healthy",
            "components": {}
        }
        
        try:
            # Redis health
            if self.redis_client:
                await self.redis_client.ping()
                health["components"]["redis"] = {"status": "healthy"}
            else:
                health["components"]["redis"] = {"status": "unhealthy", "error": "Not connected"}
        except Exception as e:
            health["components"]["redis"] = {"status": "unhealthy", "error": str(e)}
        
        # Cache health
        if self.cache_manager:
            cache_health = await self.cache_manager.health_check()
            health["components"]["cache"] = cache_health
        
        # Budget firewall health
        if self.budget_firewall:
            try:
                budget_stats = self.budget_firewall.get_statistics()
                health["components"]["budget_firewall"] = {
                    "status": "healthy",
                    "stats": budget_stats
                }
            except Exception as e:
                health["components"]["budget_firewall"] = {"status": "unhealthy", "error": str(e)}
        
        # QoS scheduler health
        if self.qos_scheduler:
            health["components"]["qos_scheduler"] = {"status": "healthy"}
        
        # Adapter health
        adapter_health = {}
        for adapter_name in self.adapter_registry.list_adapters():
            try:
                adapter = self.adapter_registry.create_instance(adapter_name, redis_client=self.redis_client)
                if hasattr(adapter, 'get_adapter_health'):
                    health_result = await adapter.get_adapter_health()
                    adapter_health[adapter_name] = health_result
                else:
                    adapter_health[adapter_name] = {"status": "healthy", "message": "Basic health check passed"}
            except Exception as e:
                adapter_health[adapter_name] = {"status": "unhealthy", "error": str(e)}
        
        health["components"]["adapters"] = adapter_health
        
        # Overall status
        unhealthy_components = [
            name for name, comp in health["components"].items()
            if comp.get("status") != "healthy"
        ]
        
        if unhealthy_components:
            health["status"] = "degraded" if len(unhealthy_components) == 1 else "unhealthy"
            health["unhealthy_components"] = unhealthy_components
        
        return health
    
    async def shutdown(self):
        """Graceful shutdown of all components."""
        logger.info("ðŸ›‘ Shutting down Market Intel Brain API...")
        
        # Cancel background tasks
        for task in self.background_tasks:
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                pass
        
        # Shutdown components in reverse order
        if self.qos_scheduler:
            await self.qos_scheduler.stop()
            logger.info("âœ… QoS scheduler stopped")
        
        if self.budget_firewall:
            await self.budget_firewall.stop()
            logger.info("âœ… Budget firewall stopped")
        
        if self.cache_manager:
            await self.cache_manager.close()
            logger.info("âœ… Cache manager closed")
        
        if self.http_session:
            await self.http_session.aclose()
            logger.info("âœ… HTTP session closed")
        
        if self.redis_client:
            await self.redis_client.close()
            logger.info("âœ… Redis connection closed")
        
        logger.info("ðŸŽ¯ Market Intel Brain API shutdown complete")

# Global state instance
global_state = GlobalState()

# Lifespan management
@asynccontextmanager
async def lifespan(app: FastAPI):
    """Manage application lifespan with proper initialization and shutdown."""
    # Startup
    await global_state.initialize()
    yield
    # Shutdown
    await global_state.shutdown()

# Create FastAPI application
app = FastAPI(
    title="Market Intel Brain API",
    description="""
    Professional market data API integrating 19+ architectural layers.
    
    ## Features
    - **Unified Data Access**: Single endpoint for all data providers
    - **QoS Management**: Priority-based task scheduling
    - **Zero-Trust Security**: Encrypted credentials and audit logging
    - **Tiered Caching**: L1 (Memory) + L2 (Redis) with SWR
    - **Budget Control**: Financial firewall with cost tracking
    - **Real-time Monitoring**: Comprehensive health checks and metrics
    - **Auto-Discovery**: Dynamic adapter registration and management
    
    ## Architecture
    This API demonstrates the complete integration of:
    - Core Layer (Base adapters, HTTP infrastructure)
    - Resilience Layer (Retry, circuit breaker, error handling)
    - Caching Layer (Tiered cache with SWR)
    - Validation Layer (Pydantic models, strict typing)
    - Security Layer (Zero-trust, SecretStr)
    - Identity Layer (Session isolation)
    - Financial Operations (Budget firewall, rate limiting)
    - QoS Layer (Priority scheduling, task management)
    - Registry Layer (Dynamic adapter discovery)
    - Orchestration Layer (Dependency injection, factory patterns)
    """,
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic models for API
class DataRequest(BaseModel):
    """Request model for data endpoints."""
    provider: str = Field(..., description="Data provider name (e.g., 'binance')")
    symbol: str = Field(..., description="Trading symbol (e.g., 'BTCUSDT')")
    timeout: Optional[float] = Field(30.0, description="Request timeout in seconds")

class DataResponse(BaseModel):
    """Response model for data endpoints."""
    success: bool = Field(..., description="Request success status")
    data: Optional[UnifiedMarketData] = Field(None, description="Market data")
    error: Optional[str] = Field(None, description="Error message if failed")
    metadata: Dict[str, Any] = Field(default_factory=dict, description="Response metadata")
    timestamp: datetime = Field(default_factory=datetime.utcnow, description="Response timestamp")

class HealthResponse(BaseModel):
    """Response model for health endpoint."""
    status: str = Field(..., description="Overall system status")
    timestamp: datetime = Field(..., description="Health check timestamp")
    components: Dict[str, Any] = Field(..., description="Component health details")
    uptime: Optional[float] = Field(None, description="System uptime in seconds")

# Dependencies
async def get_global_state():
    """Dependency to get global state."""
    return global_state

# API Endpoints
@app.get("/", tags=["Root"])
async def root():
    """Root endpoint with API information."""
    return {
        "name": "Market Intel Brain API",
        "version": "1.0.0",
        "description": "Professional market data API with 19+ architectural layers",
        "docs": "/docs",
        "health": "/health",
        "data_endpoint": "/api/v1/data/{provider}/{symbol}",
        "status": "operational"
    }

@app.get("/health", response_model=HealthResponse, tags=["Monitoring"])
async def health_check(state: GlobalState = Depends(get_global_state)):
    """
    Comprehensive health check endpoint.
    
    Returns the health status of all system components including:
    - Redis connection
    - Cache system
    - Budget firewall
    - QoS scheduler
    - All registered adapters
    """
    try:
        health_data = await state._get_comprehensive_health()
        
        # Calculate uptime
        uptime = time.time() - state._start_time
        
        return HealthResponse(
            status=health_data["status"],
            timestamp=datetime.fromisoformat(health_data["timestamp"]),
            components=health_data["components"],
            uptime=uptime
        )
        
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return HealthResponse(
            status="unhealthy",
            timestamp=datetime.utcnow(),
            components={"error": str(e)},
            uptime=None
        )

@app.get("/api/v1/data/{provider}/{symbol}", response_model=DataResponse, tags=["Data"])
async def get_market_data(
    provider: str = Query(..., description="Data provider (e.g., 'binance')"),
    symbol: str = Query(..., description="Trading symbol (e.g., 'BTCUSDT')"),
    timeout: Optional[float] = Query(30.0, description="Request timeout"),
    state: GlobalState = Depends(get_global_state)
):
    """
    Unified market data endpoint.
    
    This endpoint demonstrates the complete integration of all architectural layers:
    - Uses QoS scheduler with HIGH priority for user requests
    - Applies budget firewall protection
    - Leverages tiered caching with SWR
    - Ensures zero-trust security
    - Provides comprehensive error handling and monitoring
    
    Args:
        provider: Data provider name (must be registered)
        symbol: Trading symbol to fetch
        timeout: Request timeout in seconds
    
    Returns:
        UnifiedMarketData with comprehensive metadata
    """
    start_time = time.time()
    
    try:
        # Validate provider exists
        if not state.adapter_registry.is_registered(provider):
            available_providers = state.adapter_registry.list_adapters()
            raise HTTPException(
                status_code=404,
                detail=f"Provider '{provider}' not found. Available providers: {available_providers}"
            )
        
        # Submit as HIGH priority user request through QoS scheduler
        task_id = await state.qos_scheduler.submit_user_request(
            _fetch_data_with_layers,
            provider,
            symbol,
            state,
            timeout=timeout
        )
        
        # Wait for task completion (in production, this could be async with websockets)
        # For now, we'll execute directly for simplicity
        market_data = await _fetch_data_with_layers(provider, symbol, state, timeout)
        
        # Calculate response time
        response_time = time.time() - start_time
        
        # Prepare metadata
        metadata = {
            "provider": provider,
            "symbol": symbol,
            "response_time": response_time,
            "task_id": task_id,
            "qos_priority": "HIGH",
            "cache_status": "unknown",  # Could be extracted from adapter
            "budget_checked": True
        }
        
        logger.info(f"âœ… Data request completed: {provider}/{symbol} in {response_time:.3f}s")
        
        return DataResponse(
            success=True,
            data=market_data,
            metadata=metadata,
            timestamp=datetime.utcnow()
        )
        
    except HTTPException:
        raise
    except Exception as e:
        response_time = time.time() - start_time
        logger.error(f"âŒ Data request failed: {provider}/{symbol} - {e}")
        
        return DataResponse(
            success=False,
            error=str(e),
            metadata={
                "provider": provider,
                "symbol": symbol,
                "response_time": response_time,
                "error_type": type(e).__name__
            },
            timestamp=datetime.utcnow()
        )

async def _fetch_data_with_layers(
    provider: str, 
    symbol: str, 
    state: GlobalState, 
    timeout: Optional[float] = 30.0
) -> UnifiedMarketData:
    """
    Internal function to fetch data using all architectural layers.
    
    This function demonstrates the complete layer integration:
    1. Budget firewall check
    2. Adapter retrieval from registry
    3. Data fetch with caching and retry
    4. Response normalization
    """
    try:
        # 1. Budget firewall protection
        await state.budget_firewall.check_request(
            provider=provider,
            user_id="api_user",  # Could be extracted from auth context
            operation="get_price",
            request_size=len(symbol.encode()),
            metadata={"symbol": symbol, "endpoint": "/api/v1/data"}
        )
        
        # 2. Get adapter from registry
        adapter = state.adapter_registry.create_instance(provider, redis_client=state.redis_client)
        
        # 3. Fetch data (this will use all layers: cache, retry, etc.)
        market_data = await adapter.get_price(symbol)
        
        # 4. Return normalized data
        return market_data
        
    except Exception as e:
        logger.error(f"Layer integration failed for {provider}/{symbol}: {e}")
        raise

@app.get("/api/v1/providers", tags=["Discovery"])
async def list_providers(state: GlobalState = Depends(get_global_state)):
    """
    List all available data providers.
    
    Returns information about registered adapters including their capabilities.
    """
    try:
        providers = []
        
        for provider_name in state.adapter_registry.list_adapters():
            metadata = state.adapter_registry.get_metadata(provider_name)
            
            # Get adapter health if possible
            health_info = {"status": "unknown"}
            try:
                adapter = state.adapter_registry.create_instance(provider_name, redis_client=state.redis_client)
                if hasattr(adapter, 'get_adapter_health'):
                    health_info = await adapter.get_adapter_health()
            except Exception as e:
                health_info = {"status": "error", "error": str(e)}
            
            providers.append({
                "name": provider_name,
                "metadata": metadata,
                "health": health_info
            })
        
        return {
            "success": True,
            "providers": providers,
            "count": len(providers),
            "timestamp": datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Provider listing failed: {e}")
        return {
            "success": False,
            "error": str(e),
            "providers": [],
            "timestamp": datetime.utcnow().isoformat()
        }

@app.get("/api/v1/metrics", tags=["Monitoring"])
async def get_metrics(state: GlobalState = Depends(get_global_state)):
    """
    Get comprehensive system metrics.
    
    Returns metrics from all architectural components including:
    - QoS scheduler statistics
    - Cache performance
    - Budget firewall stats
    - Adapter metrics
    """
    try:
        metrics = {
            "timestamp": datetime.utcnow().isoformat(),
            "components": {}
        }
        
        # QoS metrics
        if state.qos_scheduler and hasattr(state.qos_scheduler, 'dispatcher'):
            dispatcher_stats = state.qos_scheduler.dispatcher.get_statistics()
            metrics["components"]["qos"] = dispatcher_stats
        
        # Cache metrics
        if state.cache_manager:
            cache_stats = state.cache_manager.get_stats()
            metrics["components"]["cache"] = cache_stats
        
        # Budget firewall metrics
        if state.budget_firewall:
            budget_stats = state.budget_firewall.get_statistics()
            metrics["components"]["budget_firewall"] = budget_stats
        
        # Adapter metrics
        adapter_metrics = {}
        for provider_name in state.adapter_registry.list_adapters():
            try:
                adapter = state.adapter_registry.create_instance(provider_name, redis_client=state.redis_client)
                if hasattr(adapter, 'get_metrics'):
                    adapter_metrics[provider_name] = adapter.get_metrics()
            except Exception as e:
                adapter_metrics[provider_name] = {"error": str(e)}
        
        metrics["components"]["adapters"] = adapter_metrics
        
        return {
            "success": True,
            "metrics": metrics
        }
        
    except Exception as e:
        logger.error(f"Metrics collection failed: {e}")
        return {
            "success": False,
            "error": str(e),
            "timestamp": datetime.utcnow().isoformat()
        }

# Background task endpoint for testing
@app.post("/api/v1/background/warm-cache", tags=["Maintenance"])
async def trigger_cache_warming(
    symbols: List[str] = Query(["BTCUSDT", "ETHUSDT"], description="Symbols to warm cache for"),
    state: GlobalState = Depends(get_global_state)
):
    """
    Trigger cache warming for specific symbols.
    
    This endpoint submits background tasks with LOW priority to warm the cache.
    """
    try:
        submitted_tasks = []
        
        for symbol in symbols:
            task_id = await state.qos_scheduler.submit_background_task(
                state._warm_symbol_cache,
                symbol,
                priority=Priority.LOW,
                timeout=30.0
            )
            submitted_tasks.append({
                "symbol": symbol,
                "task_id": task_id,
                "priority": "LOW"
            })
        
        return {
            "success": True,
            "message": f"Submitted {len(submitted_tasks)} cache warming tasks",
            "tasks": submitted_tasks,
            "timestamp": datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Cache warming trigger failed: {e}")
        return {
            "success": False,
            "error": str(e),
            "timestamp": datetime.utcnow().isoformat()
        }

if __name__ == "__main__":
    import uvicorn
    
    # Run the application
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
